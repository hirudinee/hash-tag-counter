{"EDITOR_STATE":{"allProjectFiles":{"3997e3fe-fee3-4ca4-abca-233fd0da4108":{"id":"3997e3fe-fee3-4ca4-abca-233fd0da4108","parent":null,"name":"hash-tag-counter","type":"DIRECTORY","isDirectory":true,"children":["da1d74a0-ff68-4c27-b504-26a1c9e272ec","c0f71961-d190-499a-ad22-5cd3245044ce"],"isRemovable":false,"filePath":"hash-tag-counter"},"da1d74a0-ff68-4c27-b504-26a1c9e272ec":{"id":"da1d74a0-ff68-4c27-b504-26a1c9e272ec","parent":"3997e3fe-fee3-4ca4-abca-233fd0da4108","name":"lambda.js","type":"LAMBDA_FILE","isDirectory":false,"children":[],"isRemovable":true,"filePath":"hash-tag-counter/lambda.js","code":"/*\n * Original source: https://docs.aws.amazon.com/lambda/latest/dg/with-s3-example-deployment-pkg.html\n * Retrieved on:    2018-01-19\n */\n\n// Dependencies\nlet AWS = require('aws-sdk');\nlet async = require('async');\nlet util = require('util');\n// Enable ImageMagick integration.\nlet gm = require('gm').subClass({ imageMagick: true });\n\n// Get reference to S3 client.\nconst s3 = new AWS.S3();\n\n// Constants\nconst MAX_WIDTH = 100;\nconst MAX_HEIGHT = 100;\n\nexports.handler = function (event, context, callback) {\n\n    // Read options from the event.\n    console.log(\"Reading options from event:\\n\", util.inspect(event, { depth: 5 }));\n\n    // Object key may have spaces or unicode non-ASCII characters.\n    let srcKey = decodeURIComponent(event.Records[0].s3.object.key.replace(/\\+/g, \" \"));\n    let dstKey = \"thumb-\" + srcKey;\n\n    // Infer the image type.\n    let typeMatch = srcKey.match(/\\.([^.]*)$/);\n    if (!typeMatch) {\n        callback(\"Could not determine the image type.\");\n        return;\n    }\n    let imageType = typeMatch[1];\n    if (imageType != \"jpg\" && imageType != \"png\") {\n        callback(`Unsupported image type: ${imageType}`);\n        return;\n    }\n\n    // Download the image from S3, transform, and upload under new key.\n    async.waterfall([\n            function download(next) {\n                // Download the image from S3 into a buffer.\n                s3.getObject({\n                    'Bucket': \"sigma-s3-thumb-input\",\n                    'Key': srcKey\n                }, next);\n            },\n            function transform(response, next) {\n                gm(response.Body).size(function (err, size) {\n                    // Infer the scaling factor to avoid stretching the image unnaturally.\n                    let scalingFactor = Math.min(\n                        MAX_WIDTH / size.width,\n                        MAX_HEIGHT / size.height\n                    );\n                    let width = scalingFactor * size.width;\n                    let height = scalingFactor * size.height;\n\n                    // Transform the image buffer in memory.\n                    this.resize(width, height)\n                        .toBuffer(imageType, function (err, buffer) {\n                            if (err) {\n                                next(err);\n                            } else {\n                                next(null, response.ContentType, buffer);\n                            }\n                        });\n                });\n            },\n            function upload(contentType, data, next) {\n                // Stream the transformed image to a different S3 bucket.\n                s3.putObject({\n                    \"Body\": data,\n                    \"Bucket\": \"sigma-s3-thumb-output\",\n                    \"Key\": dstKey,\n                    \"ACL\": \"public-read\",\n                    \"Metadata\": {\n                        \"Content-Type\": contentType\n                    }\n                }, next);\n            }\n        ], function (err) {\n            let msg;\n            if (err) {\n                msg = `Unable to resize sigma-s3-thumb-input/${srcKey} and upload to sigma-s3-thumb-output/${dstKey} due to an error: ${err}`;\n                console.error(msg);\n            } else {\n                msg = `Successfully resized sigma-s3-thumb-input/${srcKey} and uploaded to sigma-s3-thumb-output/${dstKey}`;\n                console.log(msg);\n            }\n            callback(err, msg);\n        }\n    );\n};\n","triggers":[{"resourceName":"kinesishashTagStream","config":{"StartingPosition":"TRIM_HORIZON","BatchSize":100}}],"version":1},"c0f71961-d190-499a-ad22-5cd3245044ce":{"id":"c0f71961-d190-499a-ad22-5cd3245044ce","parent":"3997e3fe-fee3-4ca4-abca-233fd0da4108","name":"push-test-data.js","type":"LAMBDA_FILE","isDirectory":false,"children":[],"isRemovable":true,"filePath":"hash-tag-counter/push-test-data.js","code":"let AWS = require('aws-sdk');\nconst kinesis = new AWS.Kinesis();\n\nexports.handler = function (event, context, callback) {\n\n\tconsole.log(\"Receiveed messages for hash tags\", event.body);\n\n\tlet hashTagMessages = JSON.parse(event.body).HashTagData;\n\thashTagMessages.forEach(hashTagMessage => {\n\t\tlet message = JSON.stringify(hashTagMessage);\n\t\tconsole.log(\"HashTag message\", message)\n\t\tkinesis.putRecord({\n\t\t\tData: message,\n\t\t\tPartitionKey: 'SocialMedia',\n\t\t\tStreamName: 'hash-tag-stream'\n\t\t}).promise()\n\t\t\t.then(putRecordData => {\n\t\t\t\tconsole.log(\"Push message successfully to hash-tag-stream with response\", putRecordData);\n\t\t\t\tlet response = {\n\t\t\t\t\t'statusCode': 200,\n\t\t\t\t\t'headers': {\n\t\t\t\t\t\t'Access-Control-Allow-Origin': '*',\n\t\t\t\t\t\t'Content-Type': 'application/json'\n\t\t\t\t\t},\n\t\t\t\t\t'body': JSON.stringify({\n\t\t\t\t\t\t'Code': 'Success',\n\t\t\t\t\t\t'Message': 'Hash tag records are successfully populated to hash-tag-stream',\n\t\t\t\t\t\t'Data': putRecordData\n\t\t\t\t\t}),\n\t\t\t\t\t'isBase64Encoded': false\n\t\t\t\t};\n\t\t\t\tcallback(null, response);\n\t\t\t})\n\t\t\t.catch(err => {\n\t\t\t\tconsole.log(\"Error while pushing message to hash-tag-stream with response\", err);\n\t\t\t\tlet response = {\n\t\t\t\t\t'statusCode': err.statusCode,\n\t\t\t\t\t'headers': {\n\t\t\t\t\t\t'Access-Control-Allow-Origin': '*',\n\t\t\t\t\t\t'Content-Type': 'application/json'\n\t\t\t\t\t},\n\t\t\t\t\t'body': JSON.stringify({\n\t\t\t\t\t\t'Code': err.code,\n\t\t\t\t\t\t'Message': err.message\n\t\t\t\t\t}),\n\t\t\t\t\t'isBase64Encoded': false\n\t\t\t\t};\n\t\t\t\tcallback(null, response);\n\t\t\t});\n\t})\n}","triggers":[{"resourceName":"apigusEast1populateHashTagDataProxypopulatepost","config":{}}],"version":1}},"rootNode":"3997e3fe-fee3-4ca4-abca-233fd0da4108","openFiles":["da1d74a0-ff68-4c27-b504-26a1c9e272ec","c0f71961-d190-499a-ad22-5cd3245044ce"],"currentFileId":"da1d74a0-ff68-4c27-b504-26a1c9e272ec","resources":{"ddbHashTags":{"name":"ddbHashTags","type":"DynamoDB","config":{"mode":0,"operation":"get","table":{"arn":"","name":"HashTags","partitionKey":"Application","partitionKeyType":"S","hasSortKey":true,"sortKey":"HashTag","sortKeyType":"S","mode":0},"isGlobalEditMode":false,"parameters":{"Key":{"Application":"ss","HashTag":"dsds"},"Item":{},"ExpressionAttributeValues":{}},"validator":{"validatableFields":{},"validity":true},"valid":true},"globallyEditable":false},"kinesishashTagStream":{"name":"kinesishashTagStream","type":"Kinesis","config":{"mode":0,"StreamName":"hash-tag-stream","shards":1,"region":"us-east-1","triggerParams":{"StartingPosition":"TRIM_HORIZON","BatchSize":100}},"globallyEditable":true},"apigusEast1populateHashTagDataProxypopulatepost":{"name":"apigusEast1populateHashTagDataProxypopulatepost","type":"API_GATEWAY","config":{"selectedRegion":"us-east-1","apiMode":0,"apiName":"populate-hash-tag-data-proxy","endpointType":"EDGE","resourceMode":0,"resourceName":"populate","resourcePath":"/populate","restMethod":"POST","proxyIntegration":true,"enableCORS":true,"stageMode":0,"stageName":"Prod"},"globallyEditable":true}},"packageJSON":{"dependencies":{"aws-sdk":{"name":"aws-sdk","version":"2.176.0","notRemovable":true},"slappforge-sdk":{"name":"@slappforge/slappforge-sdk","version":"0.0.3","notRemovable":true,"types":"\n                    declare class RDSQueryParams {\n    instanceIdentifier: string;\n    query: string;\n    inserts: Array<any>\n}\n\ndeclare namespace SL.AWS {\n    class RDS {\n        query(params: RDSQueryParams, callback: Function, connection: any): void;\n\n        beginTransaction(params: any, callback: Function): void;\n    }\n\n    class SQS {\n        receiveAndDeleteMessages(params: any, filteringCallBack: Function, deleteCallBack: Function, errorCallBack: Function): void;\n    }\n}\n"}}},"lambdaId":"da1d74a0-ff68-4c27-b504-26a1c9e272ec","additionalFiles":[]},"PROJECT_META":{"projectName":"hash-tag-counter","projectDescription":"Counting hash tags of social media posts","projectVersion":"1.0.0","projectRegion":"us-east-1","repoName":"hash-tag-counter","repoUrl":"https://github.com/hirudinee/hash-tag-counter","lastSave":1519213746428}}